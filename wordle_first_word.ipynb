{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an attempt to find the ideal first word for the Wordle game.\n",
    "\n",
    "# Load 5-letter words and split into 5 columns\n",
    "\n",
    "- - -\n",
    "\n",
    "Using Owen Yin's Wordle list from [here](https://medium.com/@owenyin/here-lies-wordle-2021-2027-full-answer-list-52017ee99e86). Analysis always starts with a good dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# using Owen Yin's Wordle list from here: \n",
    "# https://medium.com/@owenyin/here-lies-wordle-2021-2027-full-answer-list-52017ee99e86\n",
    "df = pd.read_csv('nyt.txt', header=None, names=['word'])\n",
    "\n",
    "# Filter out rows where words are not exactly 5 characters long. This should not\n",
    "# be necessary as the word list should already be limited to words that are only\n",
    "# 5 characters long.\n",
    "df = df[df['word'].str.len()==5]\n",
    "\n",
    "# split each word into its characters\n",
    "df[['char1','char2','char3','char4','char5']] = df['word'].apply(lambda x: pd.Series(list(x)))\n",
    "\n",
    "print(F\"number of words = {df.size}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze characters of each word\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The characters for each word can be analyzed to count how many times each character appears in each of the five positions of the five-character words. Calculating a sum for each row will show how many times each letter shows up overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the frequency of each letter in each position\n",
    "\n",
    "Use Pandas `value_counts()` to count the number of times characters appear in each of the five columns. The result is a 26-row dataframe (one row for each letter of the alphabet). The five columns show how many times each letter appears in that position of the words in the dataset.\n",
    "\n",
    "The `sum` column shows the totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe whose index is the alphabet\n",
    "df_freq = pd.DataFrame()\n",
    "df_freq.index = list(string.ascii_uppercase)\n",
    "\n",
    "# create value counts for each column and concat them together\n",
    "for col_name in ['char1','char2','char3','char4','char5']:\n",
    "    temp_df = df[col_name].value_counts().to_frame()\n",
    "    df_freq = pd.concat([df_freq, temp_df],axis=1)\n",
    "\n",
    "# concat can create NaN values in Pandas; replace those with zero\n",
    "df_freq.fillna(0,inplace=True)\n",
    "\n",
    "# NaN in a column forces the column to be float; convert to int\n",
    "df_freq = df_freq.astype(int)\n",
    "\n",
    "df_freq.columns = ['char1','char2','char3','char4','char5']\n",
    "\n",
    "# create a column of sums showing the total occurrences of each letter\n",
    "df_freq['sum'] = df_freq.sum(axis=1)\n",
    "df_freq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show most common letters for each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most popular characters in each position\n",
    "\n",
    "df_sorted = pd.DataFrame()\n",
    "\n",
    "# go column by column and retrieve a list of the most common characters\n",
    "# using value_counts(), which automatically sorts in descending order\n",
    "for col_name in df_freq.columns:\n",
    "    sort_list = df_freq.sort_values(by=[col_name],ascending=False).index\n",
    "    df_sorted[col_name] = sort_list\n",
    "\n",
    "df_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq.sort_values(by='sum',ascending=False)['sum'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate scores\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores based on overall popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popularity score'] = df['word'].apply(lambda word: sum(df_freq['sum'][y] for y in word))\n",
    "df.sort_values(by=['popularity score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words with double letters\n",
    "df['unique'] = df['word'].apply(lambda x: pd.Series(list(x)).unique().size==5)\n",
    "df[df['unique']].sort_values(by=['popularity score'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores based on positional popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_positional_score(row):\n",
    "    col_names = ['char1','char2','char3','char4','char5']\n",
    "    total = 0\n",
    "    for col in col_names:\n",
    "        letter = row[col]\n",
    "        total += df_freq[col][letter]\n",
    "    return total\n",
    "\n",
    "df['positional score'] = df.apply(lambda x: calc_positional_score(x),axis=1)\n",
    "df.sort_values(by=['positional score'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores based on a hybrid approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hybrid_score(word):\n",
    "    total = 0\n",
    "    # print(word)\n",
    "    for idx,letter in enumerate(word):\n",
    "        # give one point if the character \n",
    "        total += df_freq.iloc[:,idx][letter]\n",
    "        for col in ['char1','char2','char3','char4','char5']:\n",
    "            total += df_freq[col][letter]\n",
    "    return total\n",
    "\n",
    "df['hybrid score'] = df.apply(lambda x: x['popularity score'] + x['positional score'], axis=1)\n",
    "df[df['unique']==5].sort_values(by=['hybrid score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need the character columns in our main dataframe anymore\n",
    "\n",
    "df.drop(labels=['char1','char2','char3','char4','char5'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words with the most unique vowels or consonants\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a point for each unique vowel in a word\n",
    "def score_vowels(val):\n",
    "    total = 0\n",
    "    for letter in 'AEIOUY':\n",
    "        if letter in val:\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "df['vowels'] = df['word'].apply(lambda x: score_vowels(x))\n",
    "df.sort_values(by=['vowels','popularity score','positional score'], ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a point for each consonant in the word\n",
    "def score_consonants(val):\n",
    "    total = 0\n",
    "    for letter in val:\n",
    "        if letter in 'BCDFGHJKLMNPQRSTVWXZ':\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "df['consonants'] = df['word'].apply(lambda x: score_consonants(x))\n",
    "df.sort_values(by=['consonants','popularity score','positional score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for patterns\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'EAROT'\n",
    "\n",
    "df['pattern'] = df['word'].apply(lambda word: sum(1 for letter in pattern if letter in word))\n",
    "df.sort_values(['pattern','popularity score','positional score'], ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
