{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 5-letter words and count unique characters\n",
    "\n",
    "- - -\n",
    "\n",
    "Using Owen Yin's Wordle list from [here](https://medium.com/@owenyin/here-lies-wordle-2021-2027-full-answer-list-52017ee99e86)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# using Owen Yin's Wordle list from here: \n",
    "# https://medium.com/@owenyin/here-lies-wordle-2021-2027-full-answer-list-52017ee99e86\n",
    "df = pd.read_csv('nyt.txt', header=None, names=['word'])\n",
    "\n",
    "# Filter out rows where words are not exactly 5 characters long. This should not\n",
    "# be necessary as the word list should already be limited to words that are only\n",
    "# 5 characters long.\n",
    "df = df[df['word'].str.len()==5]\n",
    "\n",
    "# calculate the number of unique characters in each word\n",
    "df['unique'] = df['word'].apply(lambda x: pd.Series(list(x)).unique().size)\n",
    "\n",
    "print(F\"number of words = {df.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze characters of each word\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe that splits each word into its letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each word into 5 columns in a new dataframe in order to analyze\n",
    "# each character position separately\n",
    "df_split = df['word'].apply(lambda x: pd.Series(list(x)))\n",
    "df_split.columns = ['char1','char2','char3','char4','char5']\n",
    "df_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show most common letters for each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.DataFrame()\n",
    "\n",
    "# go column by column and retrieve a list of the most common characters\n",
    "# using value_counts(), which automatically sorts in descending order\n",
    "for colName, colVal in df_split.items():\n",
    "    popular = colVal.value_counts().head().index.tolist()\n",
    "    df_common[colName] = popular\n",
    "\n",
    "# rename the dataframe indices for readability\n",
    "idx = {0:'first',1:'second',2:'third',3:'fourth',4:'fifth'}\n",
    "df_common.rename(index=idx,inplace=True)\n",
    "df_common.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show most popular letters overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity = pd.Series([],dtype=int)\n",
    "for col in list(df_split):\n",
    "    popularity = popularity.add(df_split[col].value_counts(), fill_value=0)\n",
    "\n",
    "popularity.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate scores\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores based on character position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate a score based on the rank of each character position. For the given\n",
    "WORD, award POINTS if its characters match the corresponding location in LETTERS.\n",
    "\"\"\"\n",
    "def calc_positional_score(word, letters, points):\n",
    "    total = 0\n",
    "    for idx, val in enumerate(list(word)):\n",
    "        if val == letters[idx]:\n",
    "            total += points\n",
    "    return total\n",
    "\n",
    "\n",
    "df['positional score'] = 0\n",
    "\n",
    "# Step through the first 3 rows of the most popular letters for each character position\n",
    "# and award points for words whose characters match those popular characters.\n",
    "for idy in range(3):\n",
    "    letters = df_common.iloc[idy].tolist()\n",
    "    df['positional score'] += df['word'].apply(\n",
    "        lambda x: calc_positional_score(x, letters, 5-idy)\n",
    "    )\n",
    "\n",
    "df.sort_values(by=['positional score'], ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores based on character popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popularity score'] = df['word'].apply(lambda word: sum(popularity[y] for y in word))\n",
    "df.sort_values(by=['popularity score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words with double letters\n",
    "df[df['unique']==5].sort_values(by=['popularity score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores based on a hybrid approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe whose index is the alphabet\n",
    "df_hybrid = pd.DataFrame()\n",
    "df_hybrid.index = list(string.ascii_uppercase)\n",
    "\n",
    "# concat the value counts of the letters of the alphabet for each character position\n",
    "for letter in ['char1','char2','char3','char4','char5']:\n",
    "    df_hybrid = pd.concat([df_hybrid, df_split[letter].value_counts().to_frame()],axis=1)\n",
    "\n",
    "# concat can create NaN values in Pandas; replace those with zero\n",
    "df_hybrid.fillna(0,inplace=True)\n",
    "# the presence of NaN in a column force the column to be float; convert to int\n",
    "df_hybrid = df_hybrid.astype(int)\n",
    "df_hybrid.columns = ['char1','char2','char3','char4','char5']\n",
    "df_hybrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hybrid_score(word):\n",
    "    total = 0\n",
    "    # print(word)\n",
    "    for idx,letter in enumerate(word):\n",
    "        # give one point if the character \n",
    "        total += df_hybrid.iloc[:,idx][letter]\n",
    "        for col in ['char1','char2','char3','char4','char5']:\n",
    "            total += df_hybrid[col][letter]\n",
    "    return total\n",
    "\n",
    "df['hybrid score'] = df['word'].apply(lambda x: calc_hybrid_score(x))\n",
    "df[df['unique']==5].sort_values(by=['hybrid score','popularity score','positional score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words with the most unique vowels or consonants\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a point for each unique vowel in a word\n",
    "def score_vowels(val):\n",
    "    total = 0\n",
    "    for letter in 'AEIOUY':\n",
    "        if letter in val:\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "df['vowels'] = df['word'].apply(lambda x: score_vowels(x))\n",
    "df.sort_values(by=['vowels','popularity score','positional score'], ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a point for each consonant in the word\n",
    "def score_consonants(val):\n",
    "    total = 0\n",
    "    for letter in val:\n",
    "        if letter in 'BCDFGHJKLMNPQRSTVWXZ':\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "df['consonants'] = df['word'].apply(lambda x: score_consonants(x))\n",
    "df.sort_values(by=['consonants','popularity score','positional score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for patterns\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'EAROT'\n",
    "\n",
    "df['pattern'] = df['word'].apply(lambda word: sum(1 for letter in pattern if letter in word))\n",
    "df.sort_values(['pattern','popularity score','positional score'], ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
